---
title: "p8105_hw2_lz2586"
author: "Lyuou Zhang"  
date: "9/29/2018"
output: 
  github_document:
    toc: true
---
```{r setup, include=FALSE}
library(tidyverse)
options(tibble.print_min = 5)
library(readxl)
library(p8105.datasets)
```

## Problem 1

```{r problem_1}
# Import transit data and data cleaning
transit <- read_csv(file = './data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv') %>% 
  janitor::clean_names() %>% 
  select(line, station_name, lat = station_latitude, long = station_longitude, route1:entry, vending, ada) %>% 
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE))
summary(transit)
dim(transit)

# Route 8, 9, 10 and 11 are imported as numeric. Need to be converted to character.
transit$route8 <- as.character(transit$route8)
transit$route9 <- as.character(transit$route9)
transit$route10 <- as.character(transit$route10)
transit$route11 <- as.character(transit$route11)

# maybe it would be better to convert vending to logical too
transit <- mutate(transit, vending = recode(vending, 'YES' = TRUE, 'NO' = FALSE))
# distinct stations
d_transit <- distinct(transit, line, station_name, ada)
summary(d_transit)
# There are 465 distinct stations, and 84 of them are ADA compliant.
# proportion of station antrances/exits without vending allow entrance
filter(transit, vending == FALSE & entry == TRUE)
filter(transit, vending == FALSE)
# 69 of them are without vending but allow entrance. There are 183 station entrances/exits without vending.
69/183

# tidying data cont.
transit_tidy <- gather(transit, key = route, value = train, route1:route11) 
transit_tidy <- separate(transit_tidy, route, into = c('remove', 'route'), sep = -1) %>%
  select(-remove)
transit_tidy_d <- distinct(transit_tidy, line, station_name, ada, train)
filter(transit_tidy_d, train == 'A')
filter(transit_tidy_d, train == 'A' & ada == TRUE)
# 60 distinct stations serve the A train, and 17 of them are ADA compliant
```

I have imported the dataset, cleaned the names, convert variables with "yes" or "no" to logical variables, and selected the variables that I need. I also converted the routes that were tought to be numeric by R to character. Now the dataset contains line, station name, the coordinates of each station, entrance type, entry, vending, ada compliance and train routes. Before I tidy the dataset, the dimension is 1868(row)*19(column). These data is not tidy.  
  
Answer for the questions:  
* There are **465** distinct stations.  
* **84** of these stations are ADA compliant.  
* **37.7** of stations entrances/exits without vending allow entrance.  
  
After I tidy the data so that route number and route name are distinct variables:  
* **60** distinct stations serve the A train.  
* Of the stations that serve the A train, **17** of them are ADA compliant.  

## Problem 2

```{r problem_2}
# Import the Trash Wheel sheet data and data cleaning
trashwheel <- read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', sheet = 'Mr. Trash Wheel', range = 'A2:N338') %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(spball_round = round(sports_balls, digits = 0))
# Convert the rounded sports ball variable to integer
trashwheel$spball_round <- as.integer(trashwheel$spball_round)

# Import and clean precipitation data
# precipitation 2016
precip_16 <- read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', sheet = '2016 Precipitation', range = 'A2:B14') %>% 
  janitor::clean_names() %>% 
  mutate(year = '2016') %>% 
  rename(precip = 'total')


# precipitation 2017
precip_17 <- read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', sheet = '2017 Precipitation', range = 'A2:B14') %>% 
  janitor::clean_names() %>% 
  mutate(year = '2017') %>% 
  rename(precip = 'total') %>% 
  filter(!is.na(precip))

# Combine datasets
precip_j <- bind_rows(precip_16, precip_17)
precip_j$month <- as.character(month.name[precip_j$month])
sum(precip_17$precip)

# I made a subset of data in year 2016. And calculated the median using both sports balls and the rounded sports balls.
dump_16 <- filter(trashwheel, year == '2016')
median(dump_16$sports_balls)
median(dump_16$spball_round)
# The results are both 26.

```

After cleaning, Mr. Trash Wheel dataset has **`r nrow(trashwheel)`** observations. It has the dumpster number, the date, month and year of the observation, the amount of trash measured by weight and by volume, and the amount of trash of each category (plastic bottles, cigarette butts, glass bottles, etc.)  

I also joined the precipitation data in 2016 and 2017 in a dataset called "precip_j". There are **`r nrow(precip_j)`** observations. This dataset has the precipitation data every month from 2016 to 2017.  

The total precipitation in 2017 is **`r sum(precip_17$precip)`**. The median number of sports balls in dumpster in 2016 is **`r median(dump_16$spball_round)`**.

## Problem 3

```{r BRFSS}
# I installed the packages, and brfss_smart2010 is already built in. 
# Data cleaning. I rename the variables, filter the observations by topic (overall health), select the variables, tidy the data and create a variable that sums up "excellent" and "good" responses. 
head(brfss_smart2010)
brfss_tidy <- janitor::clean_names(brfss_smart2010)
brfss_tidy <- brfss_tidy %>% 
  rename(state = 'locationabbr', county = 'locationdesc') %>% 
  mutate(topic = tolower(topic), response = tolower(response)) %>% 
  filter(topic == 'overall health') %>% 
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(excellent_or_very_good = excellent + very_good)

# Use distinct() to find distinct locations and states 
distinct(brfss_tidy, county)
distinct(brfss_tidy, state)

# Use a bar chart to find out the state which is represented the most
ggplot(brfss_tidy, aes(x = state)) + geom_bar(stat = 'count')
ggsave('count_by_state.jpeg')
# I'm also able to find out the exact count for each state.
brfss_tidy %>% 
  group_by(state) %>% 
  count()
# New Jersey has the most observations (146).

# Use group_by to find the median of excellent responses in 2002 
brfss_tidy %>% 
  group_by(year) %>% 
  summarize(median_exc = median(excellent, na.rm = T))

# The histogram of "excellent" response values in 2002 
# filter the data by year = 2002 and then use ggplot to make the histogram
brfss_tidy %>% 
  filter(year == '2002') %>% 
  ggplot(aes(x = excellent)) + geom_histogram()
ggsave('hist_excellent.jpeg')

# Scatterplot showing the proportion of 'excellent' response valus in New York County and Queens County 
# filter the data by county and use ggplot 
brfss_tidy %>% 
  filter(county == 'NY - New York County' | county == 'NY - Queens County') %>% 
  ggplot(aes(x = year, y = excellent, color = county)) + geom_point()
ggsave('point_nyq.jpeg')

```

* I used distinct() to find unique county or state. There are **404** unique locations in the dataset. Because there are **51** unique values in "state", every state is represented (including Washington D.C.). I made a bar chart to see the distribution of observations in each state. New Jersey is observed the most. I also used group_by() then count() to see the exact number of observations of New Jersey. It's **146**.  
  
* I used filter() to make a subset of BRFSS data which only contains data in 2002. The median of the 'excellent' respsonse value is **23.6** (there are two missing values that are removed).
